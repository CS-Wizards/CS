# 프로세스 주소 공간
- 프로세스 주소 공간은 코드, 데이터, 힙, 스택 등으로 나뉩니다.
## 초기화하지 않은 변수가 저장되는 곳
- 기화되지 않은 전역 변수는 BSS(Block Started by Symbol) 영역에 저장됩니다.
## Stack과 Heap의 크기와 크기가 결정되는 순간
- 스택(Stack)의 크기는 일반적으로 프로그램 실행 시 고정된 크기로 할당되며, 운영 체제가 스레드별로 관리합니다. 힙(Heap)의 크기는 동적으로 변경 가능하며, 프로그램 실행 중 메모리 할당을 통해 결정됩니다.
## 개발자가 아닌 사용자가 이 크기를 결정할 수 있는지
- 개발자가 코드 상에서 힙을 동적으로 할당할 수 있지만, 사용자는 운영 체제나 컴파일러 설정을 통해 힙과 스택의 기본 크기를 조정할 수 있습니다. 예를 들어, ulimit 명령어를 통해 스택 크기를 변경할 수 있습니다.
## Stack과 Heap 중 접근이 더 빠른 곳
- 스택(Stack)이 더 빠릅니다. 스택은 LIFO 구조로서 데이터의 푸시와 팝이 빠르게 이루어집니다. 반면, 힙은 동적 메모리 할당과 해제를 동반하여 더 복잡하고 느립니다.
## 공간을 분할하는 이유
- 프로세스의 주소 공간을 코드, 데이터, 힙, 스택으로 나누는 이유는 효율적인 메모리 관리와 보안성을 제공하기 위함입니다. 각 영역이 담당하는 역할이 다르고, 충돌을 방지할 수 있습니다.
## 스레드의 주소 공간
- 스레드는 프로세스의 주소 공간을 공유합니다. 즉, 코드, 데이터, 힙을 공유하지만, 스택은 각 스레드마다 별도로 할당됩니다.
## "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관?
- 메모리 관리에서의 스택과 힙은 자료구조의 스택과 힙을 비유한 것입니다. 메모리 스택은 함수 호출에 따라 LIFO 방식으로 데이터를 저장하고, 힙은 동적 할당이 가능한 구조입니다.
## IPC의 Shared Memory 기법은 프로세스 주소 공간 중 들어가는 곳
- 공유 메모리는 데이터 영역이나 힙 영역과 상호작용하며, 특정 주소 공간을 여러 프로세스가 공유합니다.
# 스케쥴러
## 스케줄링 큐
- 프로세스가 시스템에 들어오면, 이들은 잡 큐에 놓여집니다. 이 큐는 시스템 안의 모든 프로세스로 구성됩니다. 메인 메모리에 존재하며, 준비 완료 상태에서 실행을 대기하는 프로세스들은 준비 완료 큐라 불리는 리스트 상에 유지됩니다. 이 큐는 일반적으로 연결 리스트로 저장 됩니다. 준비 완료 큐의 헤더는 리스트의 첫 번쨰와 마지막 PCB를 가리키는 포인터를 포함합니다. 각 PCB는 준비 완료 큐에 있는 다음 프로세스를 가리키는 포인터 필드를 가집니다.
- 시스템에는 또한 다른 큐들도 있습니다. 프로세스가 CPU를 할당받으면, 어느 정도 실행을 하고 결국에는 그만두거나, 인터럽트 되거나, 입출력 요청이 완료되는 것 같은 특별한 사건의 발생을 기다리게 됩니다. 프로세스가 디스크 같은 공유 장치에 입출력 요청을 했다고 가정하면, 시스템에는 많은 프로세스들이 있기 때문에, 디스크가 다른 프로세스들의 입출력 요청으로 바쁠 수가 있습니다. 그러므로 프로세스는 디스크를 대기해야 할 수도있습니다. 특정 입출력 장치를 대기하는 프로세스들의 리스트를 장치 큐라고 하는데 각 장치는 자신의 장치 큐를 가집니다.

  
![image](https://github.com/user-attachments/assets/5f9635c9-19e7-458b-8adb-0e306ef9aaf0)




![image](https://github.com/user-attachments/assets/a5ffd351-ecd6-4e32-a38a-e57116f31351)




- 새로운 프로세스는 처음에 준비 완료 큐에 놓입니다. 프로세스는 실행을 위해 선택될 때 즉, CPU를 할당받을 때까지 준비 완료 큐에서 대기합니다. 일단 프로세스에 CPU가 할당되어 실행되면, 여러가지 사건들 중의 하나가 발생할 수 있습니다.
- 프로세스가 입출력 요청을 하여 입출력 큐에 넣어진다.
- 프로세스가 새로운 자식 프로세스를 생성하고 자식 프로세스의 종료를 기다린다.
- 프로세스가 인터럽트 결과에 의해 강제로 CPU로부터 제거되고,준비 완료 큐에 다시 놓인다.

- 처음의 두 경우에서, 프로세스는 결국 대기 상태에서 준비완료 상태로 전환되고, 다시 준비 완료 큐에 넣어지게 됩니다. 프로세스는 종료될 때까지 이 주기를 계속하며, 종료되면 모든 큐에서 삭제되고 그 자신의 PCB와 자원을 반납합니다.
  
 
- 프로세스는 일생 동안에 다양한 스케줄링 큐들 사이를 이주합니다. 운영체제는 어떤 방식으로든지 스케줄링 목적을 위해 프로세스들을 이들 큐에서 반드시 선택해야 합니다. 선택 절차는 적절한 스케줄러에 의해 수행됩니다. 
## 단기, 중기, 장기 스케쥴러와 현재 사용하는 스케쥴러
- 일괄처리 시스템에서는 즉시 실행될 수 있는 것보다 더 많은 프로세스들이 종종 제출됩니다. 이들 프로세스들은 대용량 메모리(디스크 등)에 저장되러 나중에 실행될 때까지 그곳에 유지 됩니다. 장기 스케줄러(잡 스케줄러)는 이 풀에서 프로세스들을 선택하여 실행하기 위해 메모리로 적재합니다. 단기 스케줄러(CPU 스케줄러)는 실행 준비가 완료되어 있는 프로세스들 중에서 선택하여, 이들 중 하나에게 CPU를 할당 합니다.
- 시분할 시스템과 같은 일부 운영체제들은 추가로 중간 수준의 스케줄링을 도입합니다. 이와 같은 중기 스케줄러의 핵심 아이디어는 메모리에서 프로세스들을 제거함으로써 다중 프로그래밍의 정도를 완화하는 것이 가끔 바람직할 수 있다는 것입니다. 차후에 다시 프로세스를 메모리로 불러와서 중단 되었던 지점에서부터 실행을 재개합니다. 이러한 기법을 스와핑 이라고 합니다. 프로세스는 중기 스케줄러에 의해서 스왑되어 나가고 후에 다시 스왑되어 들어옵니다. 스와핑은 프로세스 혼합 상태를 개선하기 위하여 필요하기도 하며. 메모리 요구량의 변화가 가용 메모리에 비해 너무 많은 요청을 했기 때문에 메모리를 자유화 시키기 위해 필요하기도 합니다.

- 현대 운영 체제는 대부분 단기 스케줄러를 자주 사용합니다. 중기 스케줄러와 장기 스케줄러는 특수한 경우에만 사용됩니다.
## 프로세스의 스케쥴링 상태

![image](https://github.com/user-attachments/assets/e75f0800-d1cf-4eec-8742-9c0fb8b8aa8a)

- 새로운(new):프로세스가 생성 중이다.
- 실행(running): 명령어들이 실행되고 있다.
- 대기(waiting): 프로세스가 어떤 사건이 일어나기를 기다리는 중이다.
- 준비 완료(ready): 프로세스가 처리기에 할당되기를 기다린다.
- 종료(terminated): 프로세스의 실행이 종료되었다.

## preemptive/non-preemptive 에서 존재할 수 없는 상태
- 모든 상태가 존재 할수 있습니다. 다만, preemptive에서는 모든 상태 전환이 자유롭습니다. Running 상태에서도 프로세스가 강제로 CPU를 양보할 수 있으므로, Running → Ready 전환이 가능합니다. non-preemptive에서는 프로세스가 스스로 CPU 사용을 끝내지 않는 한, Running → Ready로 강제 전환되는 상황은 발생하지 않습니다.
## Memory가 부족할 경우, Process의 상태 변화
- 메모리가 부족할 때는 대기(Waiting) 상태에 있는 프로세스 또는 준비(Ready) 상태에 있는 프로세스가 영향을 받습니다. 특히, 운영 체제는 메모리 부족 상태에서 우선적으로 스왑(swap)이라는 메커니즘을 사용하여 메모리를 확보합니다.
- 메모리가 부족할 경우 프로세스는 대기 상태로 전환되거나 페이지 폴트가 발생하여 스왑 인/아웃이 반복되며, 이는 시스템 성능에 영향을 미칩니다. 프로세스가 계속 대기 상태에 머무르면 시스템 전반에 걸쳐 스레싱이 발생할 수 있고, 이 경우 운영 체제는 성능을 보호하기 위해 일부 프로세스를 종료할 수 있습니다.
- 메모리가 부족할 경우, 특정 페이지에 접근하려는 프로세스가 그 페이지가 메모리에 없는 경우 페이지 폴트가 발생합니다.

페이지 폴트가 발생하면 해당 프로세스는 대기 상태로 전환되어 메모리가 할당될 때까지 대기해야 합니다.
이 과정에서 운영 체제는 불필요한 페이지를 스왑 아웃하고, 필요한 페이지를 메모리에 스왑 인한 후 프로세스는 다시 Ready 상태로 돌아가고, 차례가 되면 Running 상태로 복귀할 수 있습니다.
-스왑이 너무 빈번하게 발생하여 대부분의 CPU 시간이 페이지 스왑에만 소모되는 상황을 스레싱(Thrashing)이라고 합니다.

스레싱이 발생하면, 메모리 관리 성능이 극도로 저하되며 프로세스들이 계속해서 대기(Waiting) 상태로 머물게 됩니다.
이런 경우, 운영 체제는 일부 프로세스의 우선순위를 낮추거나 종료시키는 등의 방식으로 스레싱을 완화하려고 시도합니다.
# 컨텍스트 스위칭

## 컨텍스트 스위칭이 발생했을 때 프로세스와 스레드의 차이
- 프로세스 컨텍스트 스위칭은 프로세스 전체의 주소 공간을 전환해야 하므로 더 무겁습니다. 스레드의 컨텍스트 스위칭은 스택과 레지스터 정보만 변경됩니다.
## 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보가 커널스택에 저장되는 형식
- 컨텍스트 스위칭 시 레지스터 상태, 프로그램 카운터, 스택 포인터 등이 커널 스택에 저장됩니다.
## 컨텍스트 스위칭이 발생하는 시점
- 타임 슬라이스가 끝나거나, IO 작업이 필요할 때, 또는 우선순위가 높은 프로세스가 준비 상태로 들어올 때 발생합니다.
# 프로세스 스케쥴링 알고리즘

## 스케줄링의 개념 
단일 처리 시스템에서는 프로세스a가 진행될때 프로세스b가 입출력을 요철하면 b는 이전의 프로세스a가 자원을 놓을때까지 대기하고 있어야합니다. 하지만 다중 프로그래밍에서는 여러 프로세스들이 동시에 돌아갈 수 있으며, 프로세스가 자원을 요철하면 운영체제는 그 자원을 적절히 분배하여 프로세스에게 할당합니다. 
그래서 다음과 같은 장점을 얻을 수 있습니다.

프로세스 처리율(시간 당 작업량)을 늘릴 수 있습니다.
프로세스는 필요한 자원을 할당 받기 위해 큐에 대기합니다. 그래서 그 큐에 있는 프로세스를 어떻게 스케쥴링하는지가 프로세스 스케줄링 알고리즘이라고 합니다.
대기시간 : 자원의 할당을 대기하는 시간을 의미합니다.
실행시간 : 실제로 프로세스가 자원을 할당받은 다음 작업을 수행하는 시간을 의미합니다.
반환시간 : 작업을 완료하는데 소요되는 전체 시간으로 대기 시간과 실행 시간을 모두 포함합니다.

스케줄링의 종류
1.선입선처리 스케줄링(First Come First Served, First in First Out)
2.최소 작업 우선 스케줄링(Shortest Job First)
3.우선순위 스케줄링
4.라운드 로빈 스케줄링(Round-Robin)

## RR을 사용할 때, Time Slice에 따른 trade-off
라운드 로빈 스케줄링은 시분할 시스템을 위해 설계된 스케줄링 기법입니다. 이 스케줄링은 작은 단위의 시간인 시간할당향(Time-Slice)을 정의하여 그 시간 만큼 자원을 할당하는 방식입니다. 그래서 그 시간안에 작업을 끝내지 못하면 다음 프로세스가 다시 그 시간만큼 자원을 할당받아씁니다.
장 : 
1) 모든 프로세스가 공정하게 스케줄링을 받을 수 있습니다.
2) 실행 큐에 프로세스의 수를 알고 있을때 유용합니다.
3) 프로세스의 짧은 응답시간을 갖고 최악의 응답시간을 알 수 있습니다.
4) 평균 대기시간이 FIFO와 SJF보다 적습니다.
단 : 
1)성능은 규정 시간량의 길이에 따라 달라지므로 작업이 비슷한 길이가 좋은데, 너무 길면 FIFO로 변하고 짧으면 문맥교환
비용이 증가합니다. 
2) 하드웨어적 타이머가 필요합니다.
3) 미완성 작업은 규정 시간량을 마친후 프로세서를 기다리니까 평균 처리 시간이 높습니다.

Time Slice의 크기는 스케줄러의 정책에 따라 결정되며, 이 크기에 따라 여러 trade-off가 발생할 수 있습니다.

1. **짧은 Time Slice의 장점:**
    - 빠른 응답 시간: 짧은 Time Slice는 프로세스 간 전환을 빈번하게 수행하므로, 사용자에 대한 응답 시간이 빨라집니다.
    - 공정한 자원 분배: 모든 프로세스가 공평한 기회를 가지고 CPU를 사용할 수 있습니다.
2. **짧은 Time Slice의 단점:**
    - 컨텍스트 스위칭 오버헤드: Time Slice가 짧을수록 프로세스 간 전환 횟수가 증가하며, 이로 인해 컨텍스트 스위칭 오버헤드가 발생할 수 있습니다. 이는 CPU 시간을 낭비하게 되어 성능 저하를 가져올 수 있습니다.
    - 스케줄러 오버헤드: 짧은 Time Slice로 인해 스케줄러가 더 자주 실행되어야 하므로, 스케줄러 자체의 오버헤드가 증가할 수 있습니다.
3. **긴 Time Slice의 장점:**
    - 컨텍스트 스위칭 오버헤드 감소: Time Slice가 길어지면 프로세스 간 전환 횟수가 감소하므로, 컨텍스트 스위칭 오버헤드가 감소합니다.
    - CPU 시간 효율성 향상: 긴 Time Slice로 인해 각 프로세스가 더 많은 연속적인 CPU 시간을 사용할 수 있습니다.
4. **긴 Time Slice의 단점:**
    - 응답 시간 증가: 긴 Time Slice는 각 프로세스가 CPU를 사용하는 시간이 길어지므로, 사용자에 대한 응답 시간이 증가할 수 있습니다.
    - 공정성 감소: 긴 Time Slice로 인해 CPU를 점유한 프로세스가 오랜 시간동안 다른 프로세스를 대기시키게 되어, 공정성이 감소할 수 있습니다.

따라서 Time Slice의 선택은 응답 시간과 CPU 시간의 효율성 사이의 균형을 찾는 문제이며, 시스템의 특성과 사용자의 요구에 따라 조절되어야 합니다.

## 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있을 때 사용하는 스케쥴링 알고리즘
- 싱글 스레드 CPU에서 상시로 돌아가야 하는 프로세스가 있는 경우, 가장 적합한 스케줄링 알고리즘은(Non-preemptive Scheduling)입니다. 비선점형 스케줄링은 프로세스가 CPU를 할당받으면 해당 프로세스가 종료되거나 대기 상태로 전환될 때까지 CPU를 계속 사용합니다.
## 동시성 vs 병렬성
- 동시성은 하나의 CPU에서 여러 작업이 겉보기로 동시에 수행되는 것을 의미하고, 병렬성은 여러 CPU에서 실제로 여러 작업을 동시에 수행하는 것을 의미합니다.
- 동시성(Concurrency):
동시성은 여러 작업이 동시에 진행되는 것처럼 보이도록 하는 개념입니다. 시간적으로 겹칠 수 있지만, 실제로는 각 작업이 동시에 실행되는 것은 아닙니다. 여러 작업이 번갈아 가며 조금씩 진행되어 마치 동시에 진행되는 것처럼 보입니다.
동시성은 단일 프로세서에서 여러 작업을 처리하거나, 여러 프로세서 간에 작업을 나누어 처리하는 등의 상황에서 발생할 수 있습니다. 이는 주로 멀티태스킹, 이벤트 기반 프로그래밍 등에 적용됩니다.
- 병렬성(Parallelism):
병렬성은 실제로 여러 작업이 동시에 실행되는 것을 의미합니다. 여러 개의 프로세서 또는 코어를 사용하여 각각의 작업을 병렬로 처리함으로써 성능을 향상시킵니다.
병렬성은 동시성을 포함하는 개념으로, 동시에 여러 작업이 진행되는 것뿐만 아니라 실제로 병렬로 실행되는 것을 강조합니다. 이는 대규모 데이터 처리, 과학 및 엔지니어링 계산, 그래픽 처리 등에 사용됩니다.

간단히 말하면, 동시성은 시간적 중첩을 통해 여러 작업이 동시에 진행되는 것처럼 보이게 하는 것이며, 병렬성은 실제로 여러 작업이 동시에 실행되는 것을 나타냅니다. 병렬성은 동시성을 달성하는 한 가지 방법이지만, 동시성과 병렬성은 서로 구별되는 두 가지 다른 컴퓨팅 개념입니다.
## 타 스케쥴러와 비교하여, Multi-level Feedback Queue가 해결하는 문제점
- 우선순위 변화에 따라 유연하게 프로세스를 처리하며, 프로세스의 기아 현상(starvation)을 방지합니다.
## 스레드의 스케줄링 알고리즘
- 스레드도 프로세스와 동일하게 Round Robin, Priority, Multi-level Queue 등의 알고리즘을 사용할 수 있습니다.
# 가상화가 무엇이고, 이것이 가상머신과 어떠한 차이가 있는지 설명해 주세요.
- 가상화: 가상화는 물리적 하드웨어를 추상화하여 여러 가상 인스턴스를 실행할 수 있게 만드는 기술입니다.

가상 머신: 가상 머신은 하이퍼바이저 위에서 OS를 포함한 전체 시스템을 가상화한 환경입니다.
## 그렇다면 Docker는 둘 중 어디에 속하나요? 왜 사람들이 Docker를 많이 채택할까요?
- Docker는 컨테이너 기반 가상화 기술로, 가상 머신과 달리 호스트 OS의 커널을 공유하며, 더 가볍고 빠르게 작동합니다.
- Docker는 빠른 배포, 이식성, 자원 효율성 등으로 많이 채택됩니다.
## 하나의 Host OS에서 돌아간다면 충분히 한 컨테이너가 다른 컨테이너에 간섭할 수 있는 위험이 있지 않을까요? 이를 어떻게 방어할 수 있을까요?
- 네임스페이스와 cgroups를 이용해 각 컨테이너의 자원 접근을 제한하고, 격리성을 유지합니다.
## Docker 위에 Docker를 올릴 순 없을까요?
- 네, 가능합니다. 이를 Docker in Docker(DIND)라고 하며, 특정 개발 및 테스트 환경에서 사용됩니다.
